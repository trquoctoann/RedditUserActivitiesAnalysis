{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa150c67-7174-4ca4-b5b7-91f658e648aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.types import *\n",
    "from utilities import (\n",
    "    send_request_reddit_get_new_post,\n",
    "    format_reddit_created_date,\n",
    "    get_last_execution_date,\n",
    "    save_new_execution_date\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f95dab84-fe2a-4297-878a-b6a421530180",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "      .builder \\\n",
    "      .appName(\"Spark Ingestion\") \\\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c60fb57-2443-40c9-9351-ac2131700809",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_path = '/home/jovyan/text_classification_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38816885-e7e1-453e-a4d1-c05de26d92ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ingest_textClassification_data(datasets_path):\n",
    "    trainPath = os.path.join(datasets_path, 'news_category_train.csv')\n",
    "    trainDataset = spark.read.option(\"header\", True).csv(trainPath)\n",
    "    testPath = os.path.join(datasets_path, 'news_category_test.csv')\n",
    "    testDataset = spark.read.option(\"header\", True).csv(testPath)\n",
    "    df = trainDataset.union(testDataset)\n",
    "    df = df.withColumnRenamed(\"description\", \"descriptions\")\n",
    "    df.write \\\n",
    "      .mode(\"append\") \\\n",
    "      .format(\"jdbc\") \\\n",
    "      .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "      .option(\"url\", \"jdbc:mysql://web-database/Web\") \\\n",
    "      .option(\"dbtable\", \"textClassification\") \\\n",
    "      .option(\"user\", \"root\") \\\n",
    "      .option(\"password\", \"123\") \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74976d8a-8d2a-4be5-b66d-05a232dabe37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_and_ingest_redditData():\n",
    "    last_time = get_last_execution_date()\n",
    "    list_link = ['https://oauth.reddit.com/r/business/new/',\n",
    "                 'https://oauth.reddit.com/r/technology/new/',\n",
    "                 'https://oauth.reddit.com/r/sports/new/',\n",
    "                 'https://oauth.reddit.com/r/worldnews/new/']\n",
    "    subreddit_url = ['https://www.reddit.com/r/business/comments/',\n",
    "                     'https://www.reddit.com/r/technology/comments/',\n",
    "                     'https://www.reddit.com/r/sports/comments/',\n",
    "                     'https://www.reddit.com/r/worldnews/comments/']\n",
    "    label_dict = {0: 'Business',\n",
    "                  1: 'Sci/Tech',\n",
    "                  2: 'Sports',\n",
    "                  3: 'World'}\n",
    "    execution_time = []\n",
    "    redditDF = pd.DataFrame(columns = ['post_id', 'descriptions', 'created_utc', 'source_url', 'post_url', 'category'])\n",
    "    for num in range(len(list_link)) :\n",
    "        reddit_response, reddit_status_code = send_request_reddit_get_new_post(list_link[num])\n",
    "        subreddit_execution_time = ''\n",
    "        subreddit_last_time = last_time[num]\n",
    "        for post in reddit_response['data']['children'] :\n",
    "            # only get posts which is after the last execution\n",
    "            if datetime.datetime.strptime(format_reddit_created_date(post['data']['created_utc']), '%Y-%m-%d %H:%M:%S')  > subreddit_last_time :\n",
    "                if post['data']['selftext'] == '' :\n",
    "                    post_id = post['data']['id']\n",
    "                    descriptions = post['data']['title']\n",
    "                    created_utc = format_reddit_created_date(post['data']['created_utc'])\n",
    "                    source_url = post['data']['url']\n",
    "                    post_url = subreddit_url[num] + post_id\n",
    "                    category = label_dict[num]\n",
    "\n",
    "                    redditDF_aux = pd.DataFrame({'post_id': [post_id], 'descriptions': [descriptions], \n",
    "                                                'created_utc': [created_utc], 'source_url': [source_url], \n",
    "                                                'post_url': [post_url], 'category': [category]})\n",
    "\n",
    "                    redditDF = pd.concat([redditDF_aux, redditDF], ignore_index = True, axis = 0)\n",
    "\n",
    "                    if subreddit_execution_time == '' : \n",
    "                        subreddit_execution_time = created_utc\n",
    "        if subreddit_execution_time == '' :\n",
    "            subreddit_execution_time = subreddit_last_time\n",
    "        execution_time.append(subreddit_execution_time)\n",
    "    schema = StructType([StructField(\"post_id\", StringType(), True), \\\n",
    "                         StructField(\"descriptions\", StringType(), True), \\\n",
    "                         StructField(\"created_utc\", StringType(), True), \\\n",
    "                         StructField(\"source_url\", StringType(), True), \\\n",
    "                         StructField(\"post_url\", StringType(), True), \\\n",
    "                         StructField(\"category\", StringType(), True)])\n",
    "    df = spark.createDataFrame(data = redditDF, schema = schema)\n",
    "    df = df.withColumn('created_utc', functions.to_timestamp(df['created_utc'], 'yyyy-MM-dd HH:mm:ss'))\n",
    "    df.write \\\n",
    "      .mode(\"append\") \\\n",
    "      .format(\"jdbc\") \\\n",
    "      .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "      .option(\"url\", \"jdbc:mysql://web-database/Web\") \\\n",
    "      .option(\"dbtable\", \"redditData\") \\\n",
    "      .option(\"user\", \"root\") \\\n",
    "      .option(\"password\", \"123\") \\\n",
    "      .save()\n",
    "    rBusiness_execution_time = execution_time[0]\n",
    "    rTechnology_execution_time = execution_time[1]\n",
    "    rSports_execution_time = execution_time[2] \n",
    "    rWorldNews_execution_time = execution_time[3]\n",
    "    save_new_execution_date(rBusiness_execution_time, rTechnology_execution_time, rSports_execution_time, rWorldNews_execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a618ef98-6dd0-443c-bf97-a587245dbbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction datetime added to History-database\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' : \n",
    "    get_and_ingest_redditData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a444bc-9c04-4954-9c12-eb5943866f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df =  spark.read \\\n",
    "      .format(\"jdbc\") \\\n",
    "      .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "      .option(\"url\", \"jdbc:mysql://web-database/Web\") \\\n",
    "      .option(\"dbtable\", \"redditData\") \\\n",
    "      .option(\"user\", \"root\") \\\n",
    "      .option(\"password\", \"123\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac75fa64-064a-458e-84ca-56ff65389ff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd7e0f-df37-48ff-9565-512cb0a632d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
