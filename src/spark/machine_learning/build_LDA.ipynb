{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4952183a-c64c-409e-a057-cd1c71d3187f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from utilities import preprocessing\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.functions import col, udf, rand, max\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4457414-baeb-4750-ad1a-a90bb945d80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TextClassificationEngine:\n",
    "    \n",
    "    def __init__(self, spark):\n",
    "        logger.info(\"Starting up text classification engine: \")\n",
    "        self.spark = spark\n",
    "        self.text_classification_data = self.__load_data_from_database()\n",
    "        self.preprocessed_data = self.__data_preprocessing()\n",
    "        self.hashing_tf, self.idf_vectorizer, self.rescaled_data = self.__vectorize_data()\n",
    "        self.model = self.__train_model() \n",
    "    \n",
    "    def __load_data_from_database(self) :\n",
    "        logger.info(\"Loading labled data...\")\n",
    "        text_classification_data = spark.read \\\n",
    "                                        .format(\"jdbc\") \\\n",
    "                                        .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "                                        .option(\"url\", \"jdbc:mysql://web-database/Web\") \\\n",
    "                                        .option(\"dbtable\", \"textClassification\") \\\n",
    "                                        .option(\"user\", \"root\") \\\n",
    "                                        .option(\"password\", \"123\") \\\n",
    "                                        .load()\n",
    "        text_classification_data = text_classification_data.select('category', 'descriptions')\n",
    "        text_classification_data = text_classification_data.dropna(subset = ('category'))\n",
    "        logger.info(\"Loading completed\")\n",
    "        return text_classification_data\n",
    "\n",
    "    def __data_preprocessing(self):\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        preprocessed_data = preprocessing(self.text_classification_data, 'descriptions')\n",
    "        logger.info(\"Preprocessing completed\")\n",
    "        return preprocessed_data\n",
    "    \n",
    "    def __vectorize_data(self):\n",
    "        logger.info(\"Vectorize data...\")\n",
    "        hashing_tf = HashingTF(inputCol = \"filtered\", outputCol = \"raw_features\", numFeatures=10000)\n",
    "        featurized_data = hashing_tf.transform(self.preprocessed_data)\n",
    "\n",
    "        idf = IDF(inputCol = \"raw_features\", outputCol = \"features\")\n",
    "        idf_vectorizer = idf.fit(featurized_data)\n",
    "        rescaled_data = idf_vectorizer.transform(featurized_data)\n",
    "        logger.info(\"Vectorization completed\")\n",
    "        return hashing_tf, idf_vectorizer, rescaled_data\n",
    "\n",
    "    def __train_model(self):\n",
    "        labelEncoder = StringIndexer(inputCol = 'category',outputCol = 'label').fit(self.rescaled_data)\n",
    "        df = labelEncoder.transform(self.rescaled_data)\n",
    "        \n",
    "        family = 'multinomial'\n",
    "        regParam = 0.3\n",
    "        elasticNetParam = 0\n",
    "        maxIter = 50\n",
    "        \n",
    "        logger.info(\"Training text classification model...\")\n",
    "        lr = LogisticRegression(featuresCol = 'features',\n",
    "                                labelCol = 'label',\n",
    "                                family = family,\n",
    "                                regParam = regParam,\n",
    "                                elasticNetParam = regParam,\n",
    "                                maxIter = maxIter)\n",
    "        model = lr.fit(df)\n",
    "        logger.info(\"Text classification model built!\")\n",
    "        return model\n",
    "    \n",
    "    def predict_label(self, input_data):\n",
    "        schema = StructType([StructField(\"post_id\", StringType(), True)\\\n",
    "                            ,StructField(\"descriptions\", StringType(), True)])\n",
    "        input_df = self.spark.createDataFrame(data = input_data, schema = schema)\n",
    "        input_df = preprocessing(input_df, 'descriptions')\n",
    "        \n",
    "        featurized_input_df = self.hashing_tf.transform(input_df)\n",
    "        rescaled_input_df = self.idf_vectorizer.transform(featurized_input_df) \n",
    "        predictions = self.model.transform(rescaled_input_df)\n",
    "        def get_label(label): \n",
    "            label_dict = {0.0: 'Business',\n",
    "                         1.0: 'Sci/Tech',\n",
    "                         2.0: 'Sports',\n",
    "                         3.0: 'World'}\n",
    "            return label_dict[label]\n",
    "        get_label_udf = udf(get_label, StringType())\n",
    "        predictions = predictions.withColumn('label_name', get_label_udf(col('prediction')))\n",
    "        return predictions.select('post_id', 'descriptions', 'label_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4140399b-301d-4e3d-a9b5-f8fbc215eca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TopicModellingModel:\n",
    "    \n",
    "    def __init__(self, spark, label_name):\n",
    "        logger.info(\"Starting up model LDA Business: \")\n",
    "        self.spark = spark\n",
    "        self.label_name = label_name\n",
    "        self.data = self.__load_data_from_database()\n",
    "        self.preprocessed_data = self.__data_preprocessing()\n",
    "        self.vectorizer, self.wordVectors = self.__vectorize_data()\n",
    "        self.model, self.final_df = self.__train_model() \n",
    "    \n",
    "    def __load_data_from_database(self) :\n",
    "        logger.info(\"Loading data...\")\n",
    "        data = spark.read \\\n",
    "                    .format(\"jdbc\") \\\n",
    "                    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "                    .option(\"url\", \"jdbc:mysql://web-database/Web\") \\\n",
    "                    .option(\"dbtable\", \"redditData\") \\\n",
    "                    .option(\"user\", \"root\") \\\n",
    "                    .option(\"password\", \"123\") \\\n",
    "                    .load() \\\n",
    "                    .filter(col('category') == self.label_name)\n",
    "        logger.info(\"Loading completed\")\n",
    "        return data\n",
    "\n",
    "    def __data_preprocessing(self):\n",
    "        logger.info(\"Preprocessing data...\")\n",
    "        preprocessed_data = self.data.select('id', 'category', 'descriptions')\n",
    "        preprocessed_data = preprocessed_data.dropna(subset = ('category'))\n",
    "        preprocessed_data = preprocessing(preprocessed_data, 'descriptions')\n",
    "        logger.info(\"Preprocessing completed\")\n",
    "        return preprocessed_data\n",
    "    \n",
    "    def __vectorize_data(self):\n",
    "        vectorizer = CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(self.preprocessed_data)\n",
    "        wordVectors_business = vectorizer.transform(self.preprocessed_data)\n",
    "        return vectorizer, wordVectors_business\n",
    "\n",
    "    def __train_model(self):\n",
    "        k = 5\n",
    "        maxIter = 50\n",
    "        seed = 2\n",
    "        lda = LDA(k = k, maxIter = maxIter, featuresCol = 'features', seed = seed)\n",
    "        ldaModel = lda.fit(self.wordVectors)\n",
    "        final_df = ldaModel.transform(self.wordVectors)\n",
    "\n",
    "        to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n",
    "        max_index = udf(lambda x: x.index(__builtin__.max(x)) if x is not None else None, IntegerType())\n",
    "        final_df = final_df.withColumn('topicDistribution', to_array(final_df['topicDistribution']))\n",
    "        final_df = final_df.withColumn('topic', max_index(final_df['topicDistribution']))\n",
    "        logger.info(\"LDA Business model built!\")\n",
    "        return ldaModel, final_df\n",
    "    \n",
    "    def predict_topic(self, input_data):\n",
    "        input_df = preprocessing(input_data, 'descriptions')\n",
    "        input_wordVectors = self.vectorizer.transform(input_df)\n",
    "        predictions = self.model.transform(input_wordVectors)\n",
    "        \n",
    "        to_array = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))\n",
    "        max_index = udf(lambda x: x.index(__builtin__.max(x)) if x is not None else None, IntegerType())\n",
    "        predictions = predictions.withColumn('topicDistribution', to_array(predictions['topicDistribution']))\n",
    "        predictions = predictions.withColumn('topic', max_index(predictions['topicDistribution']))\n",
    "        return predictions.select('post_id', 'descriptions', 'label_name', 'topic')\n",
    "    \n",
    "    def get_recommendation(self, topic):\n",
    "        relevant_posts = self.final_df.filter(col('topic') == topic)\n",
    "        relevant_posts = relevant_posts.orderBy(rand()).limit(5).select('id')\n",
    "        recommendation = relevant_posts.join(self.data, relevant_posts.id == self.data.id, \"inner\").drop(relevant_posts.id)\n",
    "        return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98df539b-1f17-4af6-8fe5-72582cae70d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "           .appName('Build Recommendation Model') \\\n",
    "           .config(\"spark.jars\", \"mysql-connector-j-8.0.32.jar\")\\\n",
    "           .config(\"spark.driver.memory\", \"6g\") \\\n",
    "           .config(\"spark.executor.memory\", \"8g\") \\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd87ee9f-2ff3-4430-aa51-ddb73b842d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting up text classification engine: \n",
      "INFO:__main__:Loading labled data...\n",
      "INFO:__main__:Loading completed\n",
      "INFO:__main__:Preprocessing data...\n",
      "INFO:__main__:Preprocessing completed\n",
      "INFO:__main__:Vectorize data...\n",
      "INFO:__main__:Vectorization completed\n",
      "INFO:__main__:Training text classification model...\n",
      "INFO:__main__:Text classification model built!\n"
     ]
    }
   ],
   "source": [
    "label_engine = TextClassificationEngine(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c1b35b-2001-454a-a36e-bcd9a5f115a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = [('1', \"President Xi Jinping says he doesn't want a hodgepodge 'street stall economy' in Beijing, even as China's youth unemployment rates hit a record high\"),\n",
    "        ('2', \"Tech titans who are trying to live forever might soon have new ammunition: Next-gen anti-aging pills\"),\n",
    "        ('3', \"Bank of England governor says the UK is facing a wage-price spiral\"), \n",
    "        ('4', \" A group of technology companies  including Texas Instruments Inc. &lt;TXN.N&gt;, STMicroelectronics  &lt;STM.PA&gt; and Broadcom Corp. &lt;BRCM.O&gt;, on Thursday said they  will propose a new wireless networking standard up to 10 times  the speed of the current generation.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86bc9fd1-23c5-4ebe-b0fd-62b8060a0556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_label = label_engine.predict_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d62d59ce-cade-423d-8539-ed6d2b8350c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+\n",
      "|post_id|        descriptions|label_name|\n",
      "+-------+--------------------+----------+\n",
      "|      1|President Xi Jinp...|     World|\n",
      "|      2|Tech titans who a...|  Sci/Tech|\n",
      "|      3|Bank of England g...|  Business|\n",
      "|      4|A group of techno...|  Sci/Tech|\n",
      "+-------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_label.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e4c6444-7600-4bf8-9a59-01f695627779",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped_label = predicted_label.groupBy(\"label_name\").count()\n",
    "max_count = grouped_label.agg(max(\"count\")).first()[0]\n",
    "\n",
    "highest_count_groups = grouped_label.filter(col('count') == max_count)\n",
    "label_name = highest_count_groups.select('label_name').first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "265d2790-c584-4354-9603-b14c8dadf3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "considered_post = predicted_label.filter(col('label_name') == label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac652eee-1c0f-4e15-ad46-b804b16cc76e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sci/Tech'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "878e661a-116e-44f7-9813-bf40c53b0977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting up model LDA Business: \n",
      "INFO:__main__:Loading data...\n",
      "INFO:__main__:Loading completed\n",
      "INFO:__main__:Preprocessing data...\n",
      "INFO:__main__:Preprocessing completed\n",
      "INFO:__main__:LDA Business model built!\n"
     ]
    }
   ],
   "source": [
    "topic_engine = TopicModellingModel(spark, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edb80cd5-0b58-499e-84d2-12f7a8cb3f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predicted_topic = topic_engine.predict_topic(considered_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04c0fc26-8e33-42fc-9d3f-62acdc5dcf76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------+-----+\n",
      "|post_id|        descriptions|label_name|topic|\n",
      "+-------+--------------------+----------+-----+\n",
      "|      2|Tech titans who a...|  Sci/Tech|    4|\n",
      "|      4|A group of techno...|  Sci/Tech|    2|\n",
      "+-------+--------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_topic.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e5ba4bf-553b-4089-8ac9-1b5e4a8d49a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_topic = predicted_topic.groupBy(\"topic\").count()\n",
    "max_count = grouped_topic.agg(max(\"count\")).first()[0]\n",
    "\n",
    "highest_count_groups = grouped_topic.filter(col('count') == max_count)\n",
    "topic = highest_count_groups.select('topic').first()[0]\n",
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43f4042d-b034-468b-882e-6db480dcfe19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-------------------+--------------------+--------------------+--------+\n",
      "| id|post_id|        descriptions|        created_utc|          source_url|            post_url|category|\n",
      "+---+-------+--------------------+-------------------+--------------------+--------------------+--------+\n",
      "| 92|13l1sq4|One million cance...|2023-05-18 15:15:22|https://www.bbc.c...|https://www.reddi...|Sci/Tech|\n",
      "|126|13lsql9|First true EV rel...|2023-05-19 11:28:02|https://www.noteb...|https://www.reddi...|Sci/Tech|\n",
      "|130|13lt5hy|The 'world's smal...|2023-05-19 11:47:30|https://www.pcgam...|https://www.reddi...|Sci/Tech|\n",
      "|135|13ltb99|1st Solar Bike Pa...|2023-05-19 11:55:03|https://cleantech...|https://www.reddi...|Sci/Tech|\n",
      "|312|13kvzzx|How robots could ...|2023-05-18 11:15:48|https://www.canar...|https://www.reddi...|Sci/Tech|\n",
      "+---+-------+--------------------+-------------------+--------------------+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_engine.get_recommendation(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23895e02-3e20-4fe4-add8-671b38c88bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = topic_engine.get_recommendation(2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddd4087f-8198-4463-a334-6d1028243984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(id=61, post_id='13llygz', descriptions='Tech giants should help pay for 5G, say Europeâ€™s mobile operators', created_utc=datetime.datetime(2023, 5, 19, 5, 23, 41), source_url='https://www.standard.co.uk/tech/5g-mobile-internet-prices-meta-google-amazon-apple-b1082085.html', post_url='https://www.reddit.com/r/technology/comments/13llygz', category='Sci/Tech')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9d773-66e0-4740-bf8b-be0dd0b5a796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
