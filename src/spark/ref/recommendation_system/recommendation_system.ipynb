{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f99be54b-f323-46fb-855d-324922650592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc570bfa-1322-4418-89a1-e64d3fe60be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create spark session\n",
    "spark = SparkSession.builder \\\n",
    "           .appName('Build Recommendation Model') \\\n",
    "           .config(\"spark.jars\", \"mysql-connector-j-8.0.32.jar\")\\\n",
    "           .config(\"spark.driver.memory\", \"6g\") \\\n",
    "           .config(\"spark.executor.memory\", \"4g\") \\\n",
    "           .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23a873bb-a22a-42fa-b95c-15220a236e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \n",
    "    def __init__(self, spark):\n",
    "        logger.info(\"Starting up the Recommendation Engine: \")\n",
    "        self.spark = spark\n",
    "        self.movies_data, self.ratings_data, self.users_data = self.__load_data_from_database()\n",
    "        self.number_of_movie_ratings, self.movie_ID_with_avg_ratings = self.__count_and_average_ratings()\n",
    "        self.model = self.__train_model() \n",
    "    \n",
    "    def __load_data_from_database(self) :\n",
    "        logger.info(\"Loading Movies data...\")\n",
    "        movies_data = self.spark.read.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "                                .option(\"url\", \"jdbc:mysql://cap2-database/MovieLens\") \\\n",
    "                                .option(\"dbtable\", \"movies\").option(\"user\", \"root\") \\\n",
    "                                .option(\"password\", \"123\").load().rdd.cache()\n",
    "        \n",
    "        logger.info(\"Loading Ratings data...\")\n",
    "        ratings_data = self.spark.read.format(\"jdbc\").option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "                                 .option(\"url\", \"jdbc:mysql://cap2-database/MovieLens\") \\\n",
    "                                 .option(\"dbtable\", \"ratings\").option(\"user\", \"root\").option(\"password\", \"123\") \\\n",
    "                                 .option('fetchSize', '10000').option('partitionColumn', 'ratingTime')\\\n",
    "                                 .option('lowerBound', '1995-01-09 11:46:44').option('upperBound', '2018-09-26 06:59:09')\\\n",
    "                                 .option('numPartitions', '23').load().rdd\n",
    "        ratings_data = ratings_data.map(lambda x: (x[1], x[2], x[3])).cache()\n",
    "        \n",
    "        logger.info(\"Loading Users data...\")\n",
    "        users_data = ratings_data.map(lambda x: (x[0])).distinct().cache()\n",
    "        return movies_data, ratings_data, users_data\n",
    "    \n",
    "    def __count_and_average_ratings(self):\n",
    "        logger.info(\"Counting how many ratings per movie...\")\n",
    "        def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "            nratings = len(ID_and_ratings_tuple[1])\n",
    "            return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "        movie_ID_with_ratings = self.ratings_data.map(lambda x: (x[1], x[2])).groupByKey()\n",
    "        movie_ID_with_avg_ratings = movie_ID_with_ratings.map(get_counts_and_averages)\n",
    "        number_of_movie_ratings = movie_ID_with_avg_ratings.map(lambda x: (x[0], x[1][0]))\n",
    "        return number_of_movie_ratings, movie_ID_with_avg_ratings\n",
    "\n",
    "    def __train_model(self):\n",
    "        rank = 12\n",
    "        seed = 1\n",
    "        iterations = 10\n",
    "        regularization_parameter = 0.1\n",
    "        logger.info(\"Training the ALS model...\")\n",
    "        model = ALS.train(self.ratings_data, rank = rank, seed = seed, iterations = iterations, lambda_ = regularization_parameter)\n",
    "        logger.info(\"ALS model built!\")\n",
    "        return model\n",
    "\n",
    "    def __predict_ratings(self, user_and_movie):\n",
    "        predicted = self.model.predictAll(user_and_movie)\n",
    "        predicted_rating = predicted.map(lambda x: (x.product, x.rating))\n",
    "        predicted_rating_title_and_count = predicted_rating.join(self.number_of_movie_ratings)\n",
    "        predicted_rating_title_and_count = predicted_rating_title_and_count.map(lambda r: (r[0], r[1][0], r[1][1]))\n",
    "        return predicted_rating_title_and_count\n",
    "    \n",
    "    def get_top_ratings(self, user_id, movies_count = 5):\n",
    "        user_ratings_ids = self.ratings_data.filter(lambda rating: rating[0] == user_id).map(lambda x: x[1]).collect()\n",
    "        if user_ratings_ids == [] : \n",
    "            new_user_title_and_count = self.movie_ID_with_avg_ratings\n",
    "            new_user_recommendation = new_user_title_and_count.map(lambda r: (r[0], r[1][1], r[1][0]))\n",
    "            top_ratings_recommendation = new_user_recommendation.filter(lambda r: r[2]>=50000)\n",
    "            return top_ratings_recommendation.map(lambda x: (x[0], round(x[1], 1), x[2])).takeOrdered(movies_count, key=lambda x: (-x[1], -x[2]))\n",
    "        user_unrated_movies = self.movies_data.filter(lambda r: r[0] not in user_ratings_ids).map(lambda x: (user_id, x[0]))\n",
    "        ratings = self.__predict_ratings(user_unrated_movies).filter(lambda r: r[2]>=20000)\n",
    "        recommendation = ratings.map(lambda x: (x[0], round(x[1], 1), x[2])).takeOrdered(movies_count, key=lambda x: (-x[1], -x[2]))\n",
    "        return recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87de8f9b-8443-48de-89bc-7ca2a55c9d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting up the Recommendation Engine: \n",
      "INFO:__main__:Loading Movies data...\n",
      "INFO:__main__:Loading Ratings data...\n",
      "INFO:__main__:Loading Users data...\n",
      "INFO:__main__:Counting how many ratings per movie...\n",
      "INFO:__main__:Training the ALS model...\n",
      "INFO:__main__:ALS model built!\n"
     ]
    }
   ],
   "source": [
    "engine = RecommendationEngine(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5073ae34-635a-495c-9ad9-cc4a97372f2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Decimal('318'), 4.4, 97999)\n",
      "(Decimal('527'), 4.3, 71516)\n",
      "(Decimal('50'), 4.3, 62180)\n",
      "(Decimal('858'), 4.3, 60904)\n",
      "(Decimal('296'), 4.2, 92406)\n",
      "7.20061731338501\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "for movie in engine.get_top_ratings(0) : \n",
    "    print(movie)\n",
    "print(time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2128ae2-5dc4-4d76-a15f-710f7910e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
